<!DOCTYPE html>
<html lang="en"><head>

    <meta name="generator" content="Hugo 0.111.2">
    <meta name="date" content="2023-03-05T12:32:20Z">
    
    <meta charset="utf-8">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="referrer" content="no-referrer">
    
    <meta name="author" content="AdriÃ¡n Javaloy, Miguel Vasco, Petra Poklukar, Yuge Shi, Imant Daunhawer, Danica Kragic, Isabel Valera" />
    <meta name="description" content="First Workshop on Multimodal Representation Learning (ICLR 2023)" />
    <meta name="keywords" content="workshop, multimodal representation learning" />
    
    <title>MRL 2023 | Home</title>
    
    <meta property="og:title" content="Home" />
    <meta property="og:type" content="website" />
    <meta property="og:description" content="First Workshop on Multimodal Representation Learning (ICLR 2023)" />
    
    <meta name="twitter:title" content="" />
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;1,300&display=swap" rel="stylesheet"> 
    
    <link rel="canonical" href="https://mrl-workshop.github.io/iclr-2023/">
    <link rel="stylesheet" href="https://mrl-workshop.github.io/iclr-2023/styles.css">
    
    <link rel="apple-touch-icon" sizes="180x180" href="https://mrl-workshop.github.io/iclr-2023/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://mrl-workshop.github.io/iclr-2023/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://mrl-workshop.github.io/iclr-2023/favicon-16x16.png">
    <link rel="manifest" href="https://mrl-workshop.github.io/iclr-2023/site.webmanifest">

</head>
<body><section id="header">

    <div id="logo-container">
        <div id="title-inner-container">
            <a href="https://mrl-workshop.github.io/iclr-2023/"><img src="https://mrl-workshop.github.io/iclr-2023/logo.png" width="60%" id="logo"></a>
        </div>
    </div>

    <div id="title-container">
        <div id="title-inner-container">
            <div class="supertitle">First Workshop on</div>
            <div class="title"><a href="https://mrl-workshop.github.io/iclr-2023/">Multimodal Representation Learning</a></div>
            <div class="subtitle">May 5 @ ICLR 2023</div>
        </div>
    </div>

    <br>

    <div id="navigation">
        <ul>
        
            <li><strong><a href="https://mrl-workshop.github.io/iclr-2023/">About</a></strong></li>
        
            <li><strong><a href="https://mrl-workshop.github.io/iclr-2023/call-for-papers">Call for Papers</a></strong></li>
        
            <li><strong><a href="https://mrl-workshop.github.io/iclr-2023/schedule">Schedule</a></strong></li>
        
            <li><strong><a href="https://mrl-workshop.github.io/iclr-2023/speakers">Speakers</a></strong></li>
        
            <li><strong><a href="https://mrl-workshop.github.io/iclr-2023/organizers-reviewers">Organizers</a></strong></li>
        
      </ul>
    </div>

</section><section id="content">
        
    <h1 id="welcome">Welcome!</h1>
<p>You are on the page of the first workshop <strong>Multimodal Representation Learning (MRL): Perks and Pitfalls</strong>, co-located with <a href="https://iclr.cc/Conferences/2023"><strong>ICLR 2023</strong></a> in Kigali, Rwanda, on May 5, 2023.</p>
<div  style="text-align: center"><span class="alert"> We have extended the deadline until February 3, 2023, 23:59 AoE.</span></div>
<!-- <span class="alert">Most information is still preliminary and could change in the near future.</span> -->
<h2 id="about-the-workshop">About the workshop</h2>
<p>Following deep learning, multimodal machine learning has made steady progress, becoming ubiquitous in many domains. Learning representations from multiple modalities can be beneficial since different perceptual modalities can inform each other and ground abstract phenomena in a more robust, generalisable way. However, the complexity of different modalities can hinder the training process, requiring careful design of the model in order to learn meaningful representations. In light of these seemingly conflicting aspects of multimodal learning, we must improve our understanding of what makes each modality different, how they interact, and what are the desiderata of multimodal representations. With this workshop, we aim to bring the multimodal community together, promoting work on multimodal representation learning that provides systematic insights into the nature of the learned representations, as well as ways to improve and understand the training of multimodal models, both from a theoretical and empirical point of view.</p>
<h2 id="important-dates">Important Dates</h2>
<div id="dates"></div>
<!-- <span class="alert">Preliminary dates, they are subject to change.</span>  -->
<ul>
<li><strong>Paper submission start:</strong> December 20, 2022, 23:59 AoE.</li>
<li><strong>Paper submission deadline</strong>: <span class="alert"> February 3, 2023, 23:59 AoE.</span></li>
<li><strong>Notification to authors:</strong> March 5, 2023, 23:59 AoE.</li>
<li><strong>Camera-ready version:</strong> TBA.</li>
<li><strong>Workshop date:</strong> May 5, 2023.</li>
</ul>
<p>Contact us at <a href="mailto:mrl.workshop.2023@gmail.com">mrl.workshop.2023@gmail.com</a>. All dates are subject to change.</p>
<h2 id="with-support-from">With support from</h2>
  <div id="sponsor-logo-container">
      <div id="sponsor-inner-container">
          <img src="https://mrl-workshop.github.io/iclr-2023/googlelogo_color_416x140dp.png" width="25%" id="sponsor-logo">
      </div>
  </div>


    </section>
<div id="footer">
    Made with <a href="https://gohugo.io/">Hugo</a> and hosted on <a href="https://github.com/MRL-Workshop/iclr-2023">GitHub</a>.
</div>


</body>

</html>